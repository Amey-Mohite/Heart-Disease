{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Solution.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"PaY11a3qQwlQ","colab_type":"code","outputId":"3a4e90dc-6ca2-4262-de9d-540f2978eb34","executionInfo":{"status":"ok","timestamp":1565963432609,"user_tz":-330,"elapsed":1346,"user":{"displayName":"amey mohite","photoUrl":"https://lh3.googleusercontent.com/-ei8z7ILohm8/AAAAAAAAAAI/AAAAAAAAfA4/E3mBObRDVL4/s64/photo.jpg","userId":"05495948316031165946"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wUxhcAMdROkG","colab_type":"code","colab":{}},"source":["import pandas as pd\n","from sklearn.ensemble import AdaBoostClassifier,RandomForestClassifier\n","from sklearn.ensemble import GradientBoostingClassifier\n","from sklearn.metrics import confusion_matrix,accuracy_score,roc_auc_score,classification,roc_curve\n","from sklearn.model_selection import RandomizedSearchCV\n","import numpy as np\n","from sklearn.model_selection import train_test_split as tts\n","from sklearn.metrics import classification_report\n","from yellowbrick.classifier import ClassificationReport\n","from sklearn.metrics import log_loss\n","from matplotlib import pyplot\n","from numpy import array\n","from sklearn import preprocessing\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from xgboost import XGBClassifier\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.svm import SVC\n","from sklearn.ensemble import VotingClassifier\n","from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n","from sklearn.feature_selection import SelectFromModel\n","from sklearn.feature_selection import f_classif\n","from sklearn.feature_selection import mutual_info_classif\n","from sklearn.feature_selection import SelectKBest,SelectPercentile\n","from mlxtend.classifier import StackingClassifier\n","from sklearn.externals import joblib "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"D7kKBKczSCzi","colab_type":"code","colab":{}},"source":["data = pd.read_csv(\"/content/gdrive/My Drive/Heart Disease/heart.csv\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qIotFd1aSMoD","colab_type":"code","colab":{}},"source":["data.head(5)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uD1fDpxLEdtn","colab_type":"code","colab":{}},"source":["col = data.columns"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ersib7vRSN-R","colab_type":"code","colab":{}},"source":["data.isnull().sum()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AVXMBEisusZo","colab_type":"code","colab":{}},"source":["X = data.drop(['target'],1)\n","y=data['target']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cT0jD15Ev2Gt","colab_type":"code","colab":{}},"source":["X_train, X_test, y_train, y_test = tts(\n","    X,\n","    y,\n","    test_size=0.3,\n","    random_state=0)\n"," \n","X_train.shape, X_test.shape"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QLU7yQoR96Fx","colab_type":"code","colab":{}},"source":["######################################################### Feature Selection Methods ##################################################################"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WvymUWy695_1","colab_type":"code","colab":{}},"source":["##Forwards Feature Selection\n","sfs1=SFS(RandomForestClassifier(n_jobs=-1,n_estimators=100),\n","         k_features=10,\n","         forward=True,\n","         floating=False,\n","         verbose=2,\n","         scoring='roc_auc',\n","         cv=3\n","         )\n","\n","sfs1=sfs1.fit(X_train,y_train)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lmlYANwk_X7G","colab_type":"code","colab":{}},"source":["select_feat_forward= X_train.columns[list(sfs1.k_feature_idx_)]\n","print(\"Feature Selection Method - Forward Feature Selection : \",select_feat_forward)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"52BfMLYD_Zpz","colab_type":"code","colab":{}},"source":["## Backward Feature Selection\n","sfs2=SFS(RandomForestClassifier(n_jobs=1,n_estimators=100),\n","         k_features=10,\n","         forward=False,\n","         floating=False,\n","         verbose=2,\n","         scoring='roc_auc',\n","         cv=3\n","         )\n","\n","sfs2=sfs2.fit(np.array(X_train),y_train)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DtKmNBsV_etJ","colab_type":"code","outputId":"65c70c29-00ff-4980-b9bd-d4aea6318b54","executionInfo":{"status":"ok","timestamp":1565963542111,"user_tz":-330,"elapsed":62926,"user":{"displayName":"amey mohite","photoUrl":"https://lh3.googleusercontent.com/-ei8z7ILohm8/AAAAAAAAAAI/AAAAAAAAfA4/E3mBObRDVL4/s64/photo.jpg","userId":"05495948316031165946"}},"colab":{"base_uri":"https://localhost:8080/","height":67}},"source":["select_feat_backward= X_train.columns[list(sfs1.k_feature_idx_)]\n","print(\"Frature Selection Method - Backward Feature Selection : \", select_feat_backward)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Frature Selection Method - Backward Feature Selection :  Index(['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'exang', 'oldpeak', 'ca',\n","       'thal'],\n","      dtype='object')\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nw_a8YMnAjqO","colab_type":"code","colab":{}},"source":["##Mutual Information Gain\n","mi=mutual_info_classif(X_train,y_train)\n","mi=pd.Series(mi)\n","mi.index=X_train.columns\n","mi.sort_values(ascending=False)\n","mi.sort_values(ascending=False).plot.bar(figsize=(20,8))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kerBiH2IBF-U","colab_type":"code","colab":{}},"source":["sel_= SelectPercentile(mutual_info_classif,percentile=80).fit(X_train,y_train)\n","selected_feat_mutual_information=X_train.columns[sel_.get_support()]\n","print(\"Feature Selection method - Mutual Information Gain : \",selected_feat_mutual_information)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KBb6jE14BSPQ","colab_type":"code","colab":{}},"source":["##univariate Analysis\n","univariate = f_classif(X_train,y_train)\n","univariate\n","\n","univariate = pd.Series(univariate[1])\n","univariate.index=X_train.columns\n","univariate.sort_values(ascending=False,inplace=True)\n","\n","univariate.sort_values(ascending=False).plot.bar(figsize=(20,8))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3P8jqfwiCW98","colab_type":"code","colab":{}},"source":["sel_ =SelectPercentile(f_classif,percentile=80).fit(X_train,y_train)\n","selected_feat_univariate=X_train.columns[sel_.get_support()]\n","print(\"Feature Selection Method - Univariate Analysis : \",selected_feat_univariate)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pk1HAf3w93In","colab_type":"code","colab":{}},"source":["  ################################################################ Models Applied ############################################################################"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wujZ96Ia1Hf9","colab_type":"code","colab":{}},"source":["def plot_roc_curve(fpr, tpr):  \n","    plt.plot(fpr, tpr, color='orange', label='ROC')\n","    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n","    plt.xlabel('False Positive Rate')\n","    plt.ylabel('True Positive Rate')\n","    plt.title('Receiver Operating Characteristic (ROC) Curve')\n","    plt.legend()\n","    plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0Ll827URvCGM","colab_type":"code","colab":{}},"source":["#Randomise Search CV for Ada Boost Random Forest\n","n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n","max_features = ['auto', 'sqrt']\n","max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n","max_depth.append(None)\n","min_samples_split = [2, 5, 10]\n","min_samples_leaf = [1, 2, 4]\n","bootstrap = [True, False]\n","random_grid = {'n_estimators': n_estimators,\n","                'max_features': max_features,\n","                'max_depth': max_depth,\n","                'min_samples_split': min_samples_split,\n","                'min_samples_leaf': min_samples_leaf,\n","                'bootstrap': bootstrap}\n","print(random_grid)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hY3E814gvp3h","colab_type":"code","colab":{}},"source":["rf = RandomForestClassifier()\n","rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n","rf_random.fit(X_train,y_train)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GCfqBBnwxMZV","colab_type":"code","colab":{}},"source":["rf_random.best_params_"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"60tups29vxqa","colab_type":"code","colab":{}},"source":["def AdaBoost(X_train,y_train,X_test,y_test):\n","  ada = AdaBoostClassifier(RandomForestClassifier(),n_estimators= 50, random_state=42)\n","  ada.fit(X_train,y_train)\n","  print(\"Ada Boost:train set\")\n","  y_pred = ada.predict(X_train)\n","  pred=ada.predict_proba(X_test)   \n","  print(\"Ada Boost:Confusion Matrix: \", confusion_matrix(y_train, y_pred))\n","  print (\"Ada Boost:Accuracy : \", accuracy_score(y_train,y_pred)*100)\n","  print(\"Ada Boost:Test set\")\n","  y_pred = ada.predict(X_test)\n","  print(\"Ada Boost:Confusion Matrix: \", confusion_matrix(y_test, y_pred))\n","  print (\"Ada Boost:Accuracy : \", accuracy_score(y_test,y_pred)*100)\n","  #confusion Matrix\n","  matrix =confusion_matrix(y_test, y_pred)\n","  class_names=[0,1] \n","  fig, ax = plt.subplots()\n","  tick_marks = np.arange(len(class_names))\n","  plt.xticks(tick_marks, class_names)\n","  plt.yticks(tick_marks, class_names)\n","  sns.heatmap(pd.DataFrame(matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n","  ax.xaxis.set_label_position(\"top\")\n","  plt.tight_layout()\n","  plt.title('Confusion matrix', y=1.1)\n","  plt.ylabel('Actual label')\n","  plt.xlabel('Predicted label')\n","  plt.show()\n","  #ROC_AUC curve\n","  probs = ada.predict_proba(X_test) \n","  probs = probs[:, 1]  \n","  auc = roc_auc_score(y_test, probs)  \n","  print('AUC: %.2f' % auc)\n","  le = preprocessing.LabelEncoder()\n","  y_test1=le.fit_transform(y_test)\n","  fpr, tpr, thresholds = roc_curve(y_test1, probs)\n","  plot_roc_curve(fpr, tpr)\n","  #Log_Loss\n","  loss = log_loss(y_test, probs)\n","  print(\"Log Loss : \", loss)\n","  yhat = [x*0.01 for x in range(0, 101)]\n","  # evaluate predictions for a 0 true value\n","  losses_0 = [log_loss([0], [x], labels=[0,1]) for x in yhat]\n","  # evaluate predictions for a 1 true value\n","  losses_1 = [log_loss([1], [x], labels=[0,1]) for x in yhat]\n","  # plot input to loss\n","  pyplot.plot(yhat, losses_0, label='true=0')\n","  pyplot.plot(yhat, losses_1, label='true=1')\n","  pyplot.legend()\n","  pyplot.show()\n","  #Classification Report\n","  target_names = ['Yes', 'No']\n","  prediction=ada.predict(X_test)\n","  print(classification_report(y_test, prediction, target_names=target_names))\n","  classes = [\"Yes\", \"No\"]\n","  visualizer = ClassificationReport(ada, classes=classes, support=True)\n","  visualizer.fit(X_train, y_train)  \n","  visualizer.score(X_test, y_test)  \n","  g = visualizer.poof()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FkBvXxoLwEg1","colab_type":"code","colab":{}},"source":["AdaBoost(X_train[select_feat_forward],y_train,X_test[select_feat_forward],y_test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9Fufk9UJxgJ4","colab_type":"code","colab":{}},"source":["#XGBOOST\n","def XGBoost(X_train,y_train,X_test,y_test):\n","  xgb=XGBClassifier(max_depth=5, learning_rate=6, n_estimators=100, subsample=0.8, colsample_bytree=1, reg_alpha=0.5)\n","  xgb.fit(X_train,y_train)\n","  print(\"xgb Boost:train set\")\n","  y_pred = xgb.predict(X_train)\n","  pred=xgb.predict_proba(X_test)   \n","  print(\"xgb Boost:Confusion Matrix: \", confusion_matrix(y_train, y_pred))\n","  print (\"xgb Boost:Accuracy : \", accuracy_score(y_train,y_pred)*100)\n","  print(\"xgb Boost:Test set\")\n","  y_pred = xgb.predict(X_test)\n","  print(\"xgb Boost:Confusion Matrix: \", confusion_matrix(y_test, y_pred))\n","  print (\"xgb Boost:Accuracy : \", accuracy_score(y_test,y_pred)*100)\n","  #confusion Matrix\n","  matrix =confusion_matrix(y_test, y_pred)\n","  class_names=[0,1] \n","  fig, ax = plt.subplots()\n","  tick_marks = np.arange(len(class_names))\n","  plt.xticks(tick_marks, class_names)\n","  plt.yticks(tick_marks, class_names)\n","  sns.heatmap(pd.DataFrame(matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n","  ax.xaxis.set_label_position(\"top\")\n","  plt.tight_layout()\n","  plt.title('Confusion matrix', y=1.1)\n","  plt.ylabel('Actual label')\n","  plt.xlabel('Predicted label')\n","  plt.show()\n","  #ROC_AUC curve\n","  probs = xgb.predict_proba(X_test) \n","  probs = probs[:, 1]  \n","  auc = roc_auc_score(y_test, probs)  \n","  print('AUC: %.2f' % auc)\n","  le = preprocessing.LabelEncoder()\n","  y_test1=le.fit_transform(y_test)\n","  fpr, tpr, thresholds = roc_curve(y_test1, probs)\n","  plot_roc_curve(fpr, tpr)\n","  #Log_Loss\n","  loss = log_loss(y_test, probs)\n","  print(\"Log Loss : \", loss)\n","  yhat = [x*0.01 for x in range(0, 101)]\n","  # evaluate predictions for a 0 true value\n","  losses_0 = [log_loss([0], [x], labels=[0,1]) for x in yhat]\n","  # evaluate predictions for a 1 true value\n","  losses_1 = [log_loss([1], [x], labels=[0,1]) for x in yhat]\n","  # plot input to loss\n","  pyplot.plot(yhat, losses_0, label='true=0')\n","  pyplot.plot(yhat, losses_1, label='true=1')\n","  pyplot.legend()\n","  pyplot.show()\n","  #Classification Report\n","  target_names = ['Yes', 'No']\n","  prediction=xgb.predict(X_test)\n","  print(classification_report(y_test, prediction, target_names=target_names))\n","  classes = [\"Yes\", \"No\"]\n","  visualizer = ClassificationReport(xgb, classes=classes, support=True)\n","  visualizer.fit(X_train, y_train)  \n","  visualizer.score(X_test, y_test)  \n","  g = visualizer.poof()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vS27pMaQ4XM1","colab_type":"code","colab":{}},"source":["XGBoost(X_train[select_feat_forward],y_train,X_test[select_feat_forward],y_test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"R_Cp7c3W4Z40","colab_type":"code","colab":{}},"source":["#Voting Classifier\n","knn = KNeighborsClassifier()\n","params_knn = {'n_neighbors': np.arange(1, 25)}\n","knn_gs = GridSearchCV(knn, params_knn, cv=5)\n","knn_gs.fit(X_train, y_train)\n","knn_best = knn_gs.best_estimator_\n","log_reg = LogisticRegression()\n","svm = SVC(probability=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JpLCrJ1I7Bog","colab_type":"code","colab":{}},"source":["def Voting(X_train,y_train,X_test,y_test):\n","  estimators=[('KNN', knn_best), ('SVM', svm), ('Logistic', log_reg)]\n","  vc = VotingClassifier(estimators,voting='soft')  \n","  vc.fit(X_train,y_train)\n","  print(\"Voting Classifier :train set\")\n","  y_pred = vc.predict(X_train)\n","  #pred=vc.predict_proba(X_test)   \n","  print(\"Voting Classifier :Confusion Matrix: \", confusion_matrix(y_train, y_pred))\n","  print (\"Voting Classifier :Accuracy : \", accuracy_score(y_train,y_pred)*100)\n","  print(\"Voting Classifier :Test set\")\n","  y_pred = vc.predict(X_test)\n","  print(\"Voting Classifier :Confusion Matrix: \", confusion_matrix(y_test, y_pred))\n","  print (\"Voting Classifier :Accuracy : \", accuracy_score(y_test,y_pred)*100)\n","  #confusion Matrix\n","  matrix =confusion_matrix(y_test, y_pred)\n","  class_names=[0,1] \n","  fig, ax = plt.subplots()\n","  tick_marks = np.arange(len(class_names))\n","  plt.xticks(tick_marks, class_names)\n","  plt.yticks(tick_marks, class_names)\n","  sns.heatmap(pd.DataFrame(matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n","  ax.xaxis.set_label_position(\"top\")\n","  plt.tight_layout()\n","  plt.title('Confusion matrix', y=1.1)\n","  plt.ylabel('Actual label')\n","  plt.xlabel('Predicted label')\n","  plt.show()\n","  #ROC_AUC curve\n","  probs = vc.predict_proba(X_test) \n","  probs = probs[:, 1]  \n","  auc = roc_auc_score(y_test, probs)  \n","  print('AUC: %.2f' % auc)\n","  le = preprocessing.LabelEncoder()\n","  y_test1=le.fit_transform(y_test)\n","  fpr, tpr, thresholds = roc_curve(y_test1, probs)\n","  plot_roc_curve(fpr, tpr)\n","  #Log_Loss\n","  loss = log_loss(y_test, probs)\n","  print(\"Log Loss : \", loss)\n","  yhat = [x*0.01 for x in range(0, 101)]\n","  # evaluate predictions for a 0 true value\n","  losses_0 = [log_loss([0], [x], labels=[0,1]) for x in yhat]\n","  # evaluate predictions for a 1 true value\n","  losses_1 = [log_loss([1], [x], labels=[0,1]) for x in yhat]\n","  # plot input to loss\n","  pyplot.plot(yhat, losses_0, label='true=0')\n","  pyplot.plot(yhat, losses_1, label='true=1')\n","  pyplot.legend()\n","  pyplot.show()\n","  #Classification Report\n","  target_names = ['Yes', 'No']\n","  prediction=vc.predict(X_test)\n","  print(classification_report(y_test, prediction, target_names=target_names))\n","  classes = [\"Yes\", \"No\"]\n","  visualizer = ClassificationReport(vc, classes=classes, support=True)\n","  visualizer.fit(X_train, y_train)  \n","  visualizer.score(X_test, y_test)  \n","  g = visualizer.poof()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TCkgIT3H7187","colab_type":"code","colab":{}},"source":["Voting(X_train[select_feat_forward],y_train,X_test[select_feat_forward],y_test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LYld5FUT7_SB","colab_type":"code","colab":{}},"source":["#knn1 = KNeighborsClassifier()\n","#log_reg1 = LogisticRegression()\n","#svm1 = SVC(probability=True)\n","#gb = GradientBoostingClassifier(n_estimators=20, learning_rate = 0.05, max_features=2, max_depth = 2, random_state = 0)\n","ada = AdaBoostClassifier(RandomForestClassifier(bootstrap=True,max_depth= 70,max_features= 'auto',min_samples_leaf= 4,min_samples_split= 10,n_estimators= 400),n_estimators= 400, random_state=42)\n","xgb=XGBClassifier(max_depth=5, learning_rate=0.01, n_estimators=100, gamma=0,min_child_weight=1, subsample=0.8, colsample_bytree=0.8, reg_alpha=0.005)\n","rf2=RandomForestClassifier(bootstrap=True,max_depth= 70,max_features= 'auto',min_samples_leaf= 4,min_samples_split= 10,n_estimators= 400)\n","def stacking(X_train,y_train,X_test,y_test):\n","  classifiers=[xgb,rf2]\n","  sc = StackingClassifier(classifiers,meta_classifier=ada)  \n","  sc.fit(X_train,y_train)\n","  joblib.dump(sc, '/content/gdrive/My Drive/Heart Disease/stacking.pkl') \n","  print(\"Stacking Classifier :train set\")\n","  y_pred = sc.predict(X_train)\n","  #pred=vc.predict_proba(X_test)   \n","  print(\"Stacking Classifier :Confusion Matrix: \", confusion_matrix(y_train, y_pred))\n","  print (\"Stacking Classifier :Accuracy : \", accuracy_score(y_train,y_pred)*100)\n","  print(\"Stacking Classifier :Test set\")\n","  y_pred = sc.predict(X_test)\n","  print(\"Stacking Classifier :Confusion Matrix: \", confusion_matrix(y_test, y_pred))\n","  print (\"Stacking Classifier :Accuracy : \", accuracy_score(y_test,y_pred)*100)\n","  #confusion Matrix\n","  matrix =confusion_matrix(y_test, y_pred)\n","  class_names=[0,1] \n","  fig, ax = plt.subplots()\n","  tick_marks = np.arange(len(class_names))\n","  plt.xticks(tick_marks, class_names)\n","  plt.yticks(tick_marks, class_names)\n","  sns.heatmap(pd.DataFrame(matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n","  ax.xaxis.set_label_position(\"top\")\n","  plt.tight_layout()\n","  plt.title('Confusion matrix', y=1.1)\n","  plt.ylabel('Actual label')\n","  plt.xlabel('Predicted label')\n","  plt.show()\n","  #ROC_AUC curve\n","  probs = sc.predict_proba(X_test) \n","  probs = probs[:, 1]  \n","  auc = roc_auc_score(y_test, probs)  \n","  print('AUC: %.2f' % auc)\n","  le = preprocessing.LabelEncoder()\n","  y_test1=le.fit_transform(y_test)\n","  fpr, tpr, thresholds = roc_curve(y_test1, probs)\n","  plot_roc_curve(fpr, tpr)\n","  #Log_Loss\n","  loss = log_loss(y_test, probs)\n","  print(\"Log Loss : \", loss)\n","  yhat = [x*0.01 for x in range(0, 101)]\n","  # evaluate predictions for a 0 true value\n","  losses_0 = [log_loss([0], [x], labels=[0,1]) for x in yhat]\n","  # evaluate predictions for a 1 true value\n","  losses_1 = [log_loss([1], [x], labels=[0,1]) for x in yhat]\n","  # plot input to loss\n","  pyplot.plot(yhat, losses_0, label='true=0')\n","  pyplot.plot(yhat, losses_1, label='true=1')\n","  pyplot.legend()\n","  pyplot.show()\n","  #Classification Report\n","  target_names = ['Yes', 'No']\n","  prediction=sc.predict(X_test)\n","  print(classification_report(y_test, prediction, target_names=target_names))\n","  classes = [\"Yes\", \"No\"]\n","  visualizer = ClassificationReport(sc, classes=classes, support=True)\n","  visualizer.fit(X_train, y_train)  \n","  visualizer.score(X_test, y_test)  \n","  g = visualizer.poof()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GMxcWyQa86KP","colab_type":"code","colab":{}},"source":["stacking(X_train,y_train,X_test,y_test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"V1pVufET74Sx","colab_type":"code","colab":{}},"source":["###Prediction of New Datas\n","age = float(input(\"enter Value of age : \"))\t\n","# male = 1 , female = 0 \n","sex = float(input(\"enter Value of sex : \"))\n","cp = float(input(\"enter Value of cp : \"))\n","trestbps = float(input(\"enter Value of trestbps : \"))\n","chol = float(input(\"enter Value of chol : \"))\n","fbs = float(input(\"enter Value of fbs : \"))\n","restecg = float(input(\"enter Value of restecg : \"))\n","thalach = float(input(\"enter Value of thalach : \"))\n","exang = float(input(\"enter Value of exang : \"))\n","oldpeak = float(input(\"enter Value of oldpeak : \"))\n","slope = float(input(\"enter Value of slope : \"))\n","ca = float(input(\"enter Value of ca : \"))\n","thal = float(input(\"enter Value of thal : \"))\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wtLRdYCREhD5","colab_type":"code","colab":{}},"source":["col=col[:-1]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wqTj2NdIEQw1","colab_type":"code","colab":{}},"source":["output_data=[]\n","output_data.append(age)\n","output_data.append(sex)\n","output_data.append(cp)\n","output_data.append(trestbps)\n","output_data.append(chol)\n","output_data.append(fbs)\n","output_data.append(restecg)\n","output_data.append(thalach)\n","output_data.append(exang)\n","output_data.append(oldpeak)\n","output_data.append(slope)\n","output_data.append(ca)\n","output_data.append(thal)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ilf0mZp6E0yg","colab_type":"code","colab":{}},"source":["output_data=pd.DataFrame([output_data],columns = col)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HQrsM_PqFFFT","colab_type":"code","colab":{}},"source":["sc1 = joblib.load('/content/gdrive/My Drive/Heart Disease/stacking.pkl')  "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Lxc-A_85E71_","colab_type":"code","colab":{}},"source":["pred=sc1.predict(output_data)\n","print(\"Prediction for newly added data : \",pred)"],"execution_count":0,"outputs":[]}]}